{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests in R\n",
    "\n",
    "We're using the [randomForest](https://www.rdocumentation.org/packages/randomForest) package from R. \n",
    "\n",
    "The dataset is available from https://archive.ics.uci.edu/ml/datasets/Bank+Marketing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment and required packages\n",
    "\n",
    "The package *tidyverse* includes *dplyr, tidyr, readr, ggplot2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "\n",
    "suppressPackageStartupMessages(library(tidyverse))\n",
    "suppressPackageStartupMessages(library(caret))\n",
    "suppressPackageStartupMessages(library(ROCR))\n",
    "suppressPackageStartupMessages(library(randomForest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "We have 3 data sets\n",
    "1. The full bank data set with more than 41.000 entries, quite unbalanced\n",
    "2. A smaller subset - still unbalanced\n",
    "3. A balanced sample of the full data set with ~ 9200 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_default = \"../data/\"\n",
    "data_sets = c(\"bank-full\", \"bank-10percent\", \"bank-balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little helper function for loading the different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data <- function(data_set, data_dir = data_dir_default) {\n",
    "  data_set <- paste(data_dir, data_set, \".csv\", sep='')\n",
    "  read.csv(data_set)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the balanced data set first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data <- read_data(\"bank-balanced\")\n",
    "cat(\"# data rows: \", nrow(bank_data), \"- # features: \", ncol(bank_data), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the data in training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_data <- function(data, prop = 0.8) {\n",
    "\n",
    "  set.seed(4711)\n",
    "  n <- nrow(data)\n",
    "  n_train <- round(0.8 * n) \n",
    "  partition <- sample(1:n, n_train)\n",
    "  \n",
    "  first <-  data[partition,]\n",
    "  second  <-  data[-partition,]\n",
    "  \n",
    "  list(first, second)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the standard 80/20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions <- partition_data(bank_data)\n",
    "train.df <- partitions[[1]]\n",
    "test.df  <- partitions[[2]]\n",
    "\n",
    "cat(\"Number of training samples :\", nrow(train.df), \"\\n\")\n",
    "cat(\"Number of test samples     :\", nrow(test.df), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "We're using 100 trees, the default of 500 seems quite high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model <- randomForest(y ~ ., \n",
    "                      data = train.df,\n",
    "                      ntree = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the error rate goes down with the increasing number of trees. The 'yes', 'no' curves are errors on the objects in those classes. OOB is the mean prediction error on each training sample xᵢ, using only the trees that did not have xᵢ in their bootstrap sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout(matrix(c(1,2),nrow=1), width=c(4,1)) \n",
    "par(mar=c(5,4,4,0)) #No margin on the right side\n",
    "plot(model, log=\"y\")\n",
    "par(mar=c(5,0,4,2)) #No margin on the left side\n",
    "plot(c(0,1),type=\"n\", axes=F, xlab=\"\", ylab=\"\")\n",
    "legend(\"top\", colnames(model$err.rate),col=1:4,cex=0.8,fill=1:4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on the test set\n",
    "To get the predicted classes we need to call *predict.rpart* with *type=\"class\"*, for a probability matrix with *type=\"prob\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted <- function(model, data) {\n",
    "    predicted_class = predict(object = model,  \n",
    "                                newdata = data,\n",
    "                                type = \"response\")  \n",
    "\n",
    "    predicted_probs = predict(object = model,  \n",
    "                                newdata = data,   \n",
    "                                type = \"prob\")\n",
    "    predicted_probs_yes <- predicted_probs[,\"yes\"]\n",
    "    \n",
    "    return (list(predicted_class, predicted_probs_yes))\n",
    "}\n",
    "\n",
    "predicted_class_probs <- predicted(model, test.df)\n",
    "predict.class <- predicted_class_probs[[1]]\n",
    "predict.probs.yes <- predicted_class_probs[[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation <- confusionMatrix(data = predict.class,       \n",
    "                              reference = test.df$y)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy <- evaluation$overall[\"Accuracy\"]\n",
    "cat(\"Classification Accuracy : \", format(100*accuracy,digits = 4), \"%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred <- prediction(predict.probs.yes, test.df$y)\n",
    "roc_perf <- performance(pred,\"tpr\",\"fpr\")\n",
    "plot(roc_perf, colorize=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area under Curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_perf <- performance(pred,\"auc\")\n",
    "auc <- auc_perf@y.values[[1]]\n",
    "cat(\"AUC :\", format(auc,digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the effect of different number of trees grown ?\n",
    "We're creating models on different data sets with varying numbers of trees in the random forest.\n",
    "We're only evaluating the AUC on the unbalanced data sets since the accuracy doesn't really mean anything here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_and_evaluate_model <- function(data_set, ntree) {\n",
    "    data <- read_data(data_set)\n",
    "    partitions <- partition_data(data)\n",
    "    train.df <- partitions[[1]]\n",
    "    test.df  <- partitions[[2]]\n",
    "    model <- randomForest(y ~ ., \n",
    "                          data = train.df, \n",
    "                          ntree = ntree)\n",
    "\n",
    "    predicted_class_probs <- predicted(model, test.df)\n",
    "    predict.class <- predicted_class_probs[[1]]\n",
    "    predict.probs.yes <- predicted_class_probs[[2]]\n",
    "    \n",
    "    evaluation <- confusionMatrix(data = predict.class,       \n",
    "                                  reference = test.df$y)\n",
    "    \n",
    "    accuracy <- evaluation$overall[\"Accuracy\"]\n",
    "    \n",
    "    pred <- prediction(predict.probs.yes, test.df$y)\n",
    "    auc_perf <- performance(pred,\"auc\")\n",
    "    auc <- auc_perf@y.values[[1]]\n",
    "    \n",
    "    return(list(accuracy, auc))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (data_set in data_sets) {\n",
    "  message(paste(\"=====\", data_set, \"=====\"))\n",
    "  for (ntree in c(10, 20, 50, 100, 500)) {\n",
    "      result <- build_and_evaluate_model(data_set, ntree)\n",
    "      if ( data_set == \"bank-balanced\") {\n",
    "          msg <- paste(\"# trees :\", ntree, \n",
    "                       \"\\taccuracy :\", format(100*result[[1]],digits = 4), \n",
    "                       \"\\tAUC :\", format(result[[2]],digits = 4))\n",
    "      }\n",
    "      else {\n",
    "          msg <- paste(\"# trees :\", ntree, \n",
    "                       \"\\tAUC :\", format(result[[2]],digits = 4))\n",
    "      }\n",
    "      message(msg)\n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
