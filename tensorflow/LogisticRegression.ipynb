{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# turn off tensorflow deprecation warnings\n",
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input\n",
    "Read the bank data set and split into a features and a label subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = ('bank-10percent', 'bank-full', 'bank-balanced')\n",
    "bank = pd.read_csv('../data/' + data_sets[1] + '.csv')\n",
    "\n",
    "label_col = 'y'\n",
    "features = bank.drop(columns=['y'])\n",
    "label = bank[label_col]\n",
    "\n",
    "label_encoded = pd.get_dummies(label, drop_first = False)\n",
    "features_encoded = pd.get_dummies(features, drop_first = True)\n",
    "\n",
    "class_count=label_encoded.shape[1]\n",
    "feature_count=features_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data\n",
    "For logistic regression it's recommended to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "features_normalized = sc_X.fit_transform(features_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_normalized, label_encoded, test_size = 0.2, random_state = 167)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, feature_count]) \n",
    "y = tf.placeholder(tf.float32, [None, class_count]) \n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([feature_count, class_count]))\n",
    "b = tf.Variable(tf.zeros([class_count]))\n",
    "\n",
    "# Construct model\n",
    "prob = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(prob), reduction_indices=1))\n",
    "\n",
    "pred_class = tf.argmax(prob, 1);\n",
    "true_class = tf.argmax(y, 1);\n",
    "     \n",
    "_, accuracy = tf.metrics.accuracy(true_class, pred_class)\n",
    "    \n",
    "# Gradient Descent\n",
    "learning_rate = 0.1\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the variables (i.e. assign their default value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = [ \n",
    "        tf.global_variables_initializer(), \n",
    "        tf.local_variables_initializer()    # for metrics\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 100\n",
    "display_step = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        _, c, acc = sess.run([optimizer, cost, accuracy], feed_dict={x: X_train, y: y_train})\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \"Accuracy: {0:.2f} %\".format(acc*100))\n",
    "    \n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    pc, tc, acc = sess.run([pred_class, true_class, accuracy], \n",
    "                            feed_dict={x: X_test, y: y_test})\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    print(\"Confusion Matrix :\")   \n",
    "    print(confusion_matrix(tc, pc))\n",
    "    \n",
    "    print(\"Accuracy: {0:.2f} %\".format(acc*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
