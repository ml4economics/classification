{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Initialization\" data-toc-modified-id=\"Initialization-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialization</a></span></li><li><span><a href=\"#Some-helper-functions\" data-toc-modified-id=\"Some-helper-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Some helper functions</a></span></li><li><span><a href=\"#Build-a-model-with-a-variable-number-of-layers\" data-toc-modified-id=\"Build-a-model-with-a-variable-number-of-layers-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Build a model with a variable number of layers</a></span></li><li><span><a href=\"#Data-Input\" data-toc-modified-id=\"Data-Input-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data Input</a></span></li><li><span><a href=\"#Preprocess-Data\" data-toc-modified-id=\"Preprocess-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Preprocess Data</a></span></li><li><span><a href=\"#Logistic-Regression-as-a-Keras-Model\" data-toc-modified-id=\"Logistic-Regression-as-a-Keras-Model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Logistic Regression as a Keras Model</a></span></li><li><span><a href=\"#Keras-Model\" data-toc-modified-id=\"Keras-Model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Keras Model</a></span></li><li><span><a href=\"#Training-the-model\" data-toc-modified-id=\"Training-the-model-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Training the model</a></span></li><li><span><a href=\"#Evaluating-the-model\" data-toc-modified-id=\"Evaluating-the-model-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Evaluating the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-Data\" data-toc-modified-id=\"Training-Data-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Training Data</a></span></li><li><span><a href=\"#Test-Data\" data-toc-modified-id=\"Test-Data-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Test Data</a></span></li></ul></li><li><span><a href=\"#Classification-quality-for-different-network-architectures\" data-toc-modified-id=\"Classification-quality-for-different-network-architectures-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Classification quality for different network architectures</a></span><ul class=\"toc-item\"><li><span><a href=\"#One-hidden-layer\" data-toc-modified-id=\"One-hidden-layer-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>One hidden layer</a></span></li><li><span><a href=\"#Two-hidden-layers\" data-toc-modified-id=\"Two-hidden-layers-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>Two hidden layers</a></span></li><li><span><a href=\"#Multiple-hidden-layers\" data-toc-modified-id=\"Multiple-hidden-layers-10.3\"><span class=\"toc-item-num\">10.3&nbsp;&nbsp;</span>Multiple hidden layers</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Neural Networks implemented with Keras\n",
    "This notebook illustrates how to implement a neural network classifier with TensorFlow.  \n",
    "We're using the dataset from the\n",
    "[Bank Marketing Dataset from the UCI Data Repository](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# turn off tensorflow deprecation warnings\n",
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function displays a few quality measure for the classifier\n",
    "* confusion matrix\n",
    "* classification accuracy\n",
    "* area under curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(model, features, labels):\n",
    "    predictions = model.predict_classes(features)\n",
    "    conf_matrix = confusion_matrix(labels, predictions)   \n",
    "    _, accuracy = model.evaluate(features, labels, verbose=0)  \n",
    "    probabilities = model.predict(features)\n",
    "    auc = roc_auc_score(labels, probabilities)\n",
    "    return conf_matrix, accuracy, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the history of the model fit. The Keras `Model.fit` function returns a history object which  is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values. Plotting these gives a good idea about possible overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # to handle metrics keys changes in Keras 2.3\n",
    "    # see https://github.com/keras-team/keras/releases/tag/2.3.0\n",
    "    pre_23 = \"acc\" in history.history.keys()\n",
    "    acc_key     = 'acc'     if pre_23 else 'accuracy'\n",
    "    val_acc_key = 'val_acc' if pre_23 else 'val_accuracy'       \n",
    "    \n",
    "    acc = history.history[acc_key]\n",
    "    val_acc = history.history[val_acc_key]\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # \"bo\" is for \"blue dot\"\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    # b is for \"solid blue line\"\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model with a variable number of layers\n",
    "We're using a simple Keras `Sequential` model which is a linear stack of network layers. For the input and intermediate layers we're using the `ReLU` and for the final layer the `sigmoid` activation function.\n",
    "\n",
    "Obviously, there are lots of hyperparameters you can play with. This little helper just makes it easy to define models with different depths. The `layers` parameter is an array of integers each of which defines the number of nodes for a particular layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(num_inputs, layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    # first layer\n",
    "    model.add(Dense(layers[0], input_dim=num_inputs, activation='relu'))\n",
    "\n",
    "    #  intermediate layers\n",
    "    for i in range(1, len(layers)):\n",
    "        model.add(Dense(layers[i], activation='relu'))\n",
    "    \n",
    "    # final layer with a single node\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "Read the bank data set and split into a features and a label subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = ('bank-10percent', 'bank-full', 'bank-balanced')\n",
    "\n",
    "bank = pd.read_csv('../data/' + data_sets[2] + '.csv')\n",
    "\n",
    "label_col = 'y'\n",
    "label = bank[label_col]\n",
    "features = bank.drop(columns=['y'])\n",
    "\n",
    "label_encoded = pd.get_dummies(label, drop_first = True)\n",
    "features_encoded = pd.get_dummies(features, drop_first = True)\n",
    "feature_count=features_encoded.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "It's recommended to normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(features_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_normalized, label_encoded, test_size = 0.2, random_state = 167)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression as a Keras Model\n",
    "As a benchmark create and evaluate a network without any hidden layer and a `sigmoid` activation function. This corresponds to Logistic Regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = Sequential()\n",
    "logistic_model.add(Dense(1, input_dim=feature_count, activation='sigmoid')) \n",
    "logistic_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "logistic_model.fit(X_train, y_train, epochs=20)\n",
    "conf_matrix, accuracy, auc = quality(logistic_model, X_test, y_test)\n",
    "print(\"\\nConfusion Matrix:\\n{0}\".format(conf_matrix))\n",
    "print(\"\\nAccuracy: {0:.2f} %\".format(accuracy*100), \"AUC: {0:.3f} %\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model\n",
    "This is our model : it has two hidden layers with 16 and 8 nodes, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(feature_count, [16, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's output a bit more information about the model. Note that large number of parameters to be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of input features : {0}\".format(feature_count))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also draw a picture showing the network topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True, show_layer_names=False).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "When training the model we have to specify the number of epochs. An `epoch` is an iteration over the entire training set. However, gradient updates are not done using the entire set but batches of training data instead. The default batch size is 32, i.e. an iteration involves (training set size)/32 gradient updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=num_epochs, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the loss function during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the training loss keeps decreasing but the validation error doesn't decrease any more after about 10 epochs. In fact, it even increases afterwards. This indicates that the models begins to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix, accuracy, auc = quality(model, X_train, y_train)\n",
    "print(\"\\nConfusion Matrix:\\n{0}\".format(conf_matrix))\n",
    "print(\"\\nAccuracy: {0:.2f} %\".format(accuracy*100), \"AUC: {0:.3f} %\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix, accuracy, auc = quality(model, X_test, y_test)\n",
    "print(\"\\nConfusion Matrix:\\n{0}\".format(conf_matrix))\n",
    "print(\"\\nAccuracy: {0:.2f} %\".format(accuracy*100), \"AUC: {0:.3f} %\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification quality for different network architectures\n",
    "We vary the number of nodes in the hidden layers. Note that the classification quality doesn't really change. This is not particularly surprising, since the logistic regression (which is equivalent to an NN without any hidden layer) already achieves a very good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(num_inputs, layers, X_train, y_train, X_test,y_test):\n",
    "    model = make_model(num_inputs, layers)\n",
    "    print(model.summary())\n",
    "    model.fit(X_train, y_train,\n",
    "              epochs=10, \n",
    "              verbose=0)\n",
    "    _, accuracy, auc = quality(model, X_test,y_test)\n",
    "    print(\"\\nAccuracy: {0:.2f} %\".format(accuracy*100), \"AUC: {0:.3f} %\".format(auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(feature_count, [16], X_train, y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(feature_count, [16, 8], X_train, y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple hidden layers\n",
    "Finally check whether adding multiple layers makes any difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate(feature_count, [32, 16, 8, 4], X_train, y_train, X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
